#  **PRUEBA TCNICA PARA ML ENGINEER - NEQUI** 

1. ## **Propuesta de arquitectura en la nube.**

    La arquitectura a implementar se va realizar mediante las buenas pr谩cticas de MLOps, ya que permite implementar y mantener los modelos de aprendizaje autom谩tico en producci贸n de manera confiable y eficiente debido a que permite la escalabilidad del mismo. Para este caso se plantea la siguiente arquitectura como metodolog铆a de desarrollo. Esta se plantea con los respectivos servicios de GCP y librer铆as open source para el desarrollo, manteniendo la esencia de MLOps.

    ![Arquitectura](img/arquitectura_ml_gcp.png)

    Almacenamiento en Cloud Storage: Cloud Storage proporciona un almacenamiento altamente escalable y duradero para los datos sin procesar. Esto permite almacenar grandes vol煤menes de datos de manera eficiente y confiable.


    - **Procesamiento escalable con Dataflow:** Dataflow permite realizar transformaciones y limpieza de datos de manera escalable y paralela en el Data Lake de BigQuery. Esto asegura que el procesamiento de grandes conjuntos de datos se pueda llevar a cabo de manera eficiente y r谩pida.


    - **Almacenamiento en BigQuery:** BigQuery ofrece un Data Warehouse altamente escalable y totalmente administrado para almacenar datos limpios y procesados. Esto permite realizar consultas anal铆ticas complejas sobre grandes vol煤menes de datos con alto rendimiento y confiabilidad.


    - **Entrenamiento de modelos con Vertex AI:** Vertex AI proporciona herramientas y servicios para entrenar modelos de Machine Learning a gran escala de manera eficiente. Esto facilita el entrenamiento de modelos con grandes conjuntos de datos y garantiza la escalabilidad del proceso de entrenamiento.


    - **Empaquetado y almacenamiento en GCS:** El empaquetado y almacenamiento del modelo entrenado en Google Cloud Storage asegura que el modelo est茅 disponible de manera confiable para su implementaci贸n y uso en producci贸n.


    - **Validaci贸n del modelo:** Se realiza una validaci贸n exhaustiva del modelo entrenado para garantizar su calidad y precisi贸n antes de su implementaci贸n en producci贸n. Esto asegura que el modelo sea confiable y pueda manejar grandes vol煤menes de datos de manera efectiva.


    - **Monitoreo con MLflow:** Se utiliza para monitorear el modelo tanto en etapas de validaci贸n como en producci贸n. Esto proporciona visibilidad en tiempo real sobre el rendimiento del modelo y permite detectar y resolver problemas de manera proactiva.

    En la arquitectura propuesta, para la preparaci贸n de los datos se elige el servicio de Google Cloud Storage (GCS) como almacenamiento inicial de datos sin procesar debido a su escalabilidad, durabilidad y facilidad de acceso desde otros servicios de Google Cloud Platform (GCP). BigQuery se utiliza en la parte inicial de preparaci贸n debido a su capacidad para manejar grandes vol煤menes de datos de manera eficiente y realizar consultas complejas en datos estructurados. Adem谩s, mediante una Cloud Function se facilita la transferencia de datos desde GCS a BigQuery, permitiendo una carga autom谩tica y programada a trav茅s de un trigger (un scheduler) que activa la funci贸n para generar la carga por batch.
    El proceso de workflow a partir de ETL (Extrac, Transform and Load) se realizar谩 mediante Google Cloud Dataflow. Este servicio se selecciona debido a que en esta etapa se realizan transformaciones y limpieza, y Dataflow brinda la capacidad de procesar datos en tiempo real o por batch. Adem谩s, permite implementar pipelines de procesamiento de datos flexibles y escalables, lo que facilita la manipulaci贸n y transformaci贸n de grandes conjuntos de datos. Tambi茅n se considera la posibilidad de utilizar Dataform, un servicio directamente de BigQuery, para realizar las mismas tareas de flujo de trabajo.
    En cuanto a Vertex AI, se realizar谩 el entrenamiento de modelos de Machine Learning debido a su conjunto de herramientas y servicios que simplifican y automatizan el proceso de entrenamiento de modelos a gran escala. Vertex AI proporciona un entorno integrado para el desarrollo, entrenamiento, evaluaci贸n y despliegue de modelos de ML, lo que facilita la implementaci贸n de modelos en producci贸n.

2. ## **Step by step.**

    Se plantea el siguiente diagrama de secuencia y la arquitectura usando Google Cloud Platform (GCP) para las buenas pr谩cticas de MLOps.

    ![Diagrama MLOps](img/mlops.png)

    Y a continuaci贸n el diagrama de secuencia de pasos desde la ingesti贸n de datos hasta la monitorizaci贸n y el entrenamiento continuo, incluyendo la orquestaci贸n:

    ![Diagrama MLOps](img/diagrama_secuencia.png)

    El componente de orquestaci贸n desempe帽a un papel fundamental en la ejecuci贸n del pipeline de Machine Learning (ML) al coordinar las diferentes tareas involucradas en el proceso. Automatiza la ejecuci贸n del pipeline, garantizando que las tareas se realicen en el orden correcto y que los resultados de una tarea est茅n disponibles para las siguientes. Adem谩s, facilita la escalabilidad del pipeline, distribuyendo las tareas de manera eficiente y aprovechando recursos adicionales seg煤n sea necesario. 

    La orquestaci贸n tambi茅n gestiona las dependencias entre las tareas, asegurando que una tarea no comience hasta que todas sus dependencias est茅n completas y que las tareas se ejecuten en paralelo cuando sea posible. En resumen, el componente de orquestaci贸n asegura una ejecuci贸n eficiente y confiable del pipeline de ML, lo que contribuye a obtener resultados de alta calidad de manera consistente.

3. ## **Estructura de Directorios.**

    #### **Directorio para el proyecto de ML:**

    ![Diagrama MLOps](img/project_path.png)

    Para manejar la versi贸n del pipeline de preprocesamiento y los modelos entrenados en el directorio de modelos, puedes seguir estas pr谩cticas:

    **Control de versiones con Git:** Utiliza un sistema de control de versiones como Git para rastrear cambios en el c贸digo y los modelos. Cada vez que realices cambios en el pipeline de preprocesamiento o entrenes un nuevo modelo, haz un commit y etiqueta la versi贸n correspondiente.

    **Directorio de modelos entrenados:** Mant茅n un directorio separado para almacenar modelos entrenados, organizados por versi贸n y tipo de modelo. Por ejemplo, puedes tener subdirectorios para cada versi贸n del modelo y dentro de ellos subdirectorios para cada tipo de modelo entrenado.

    **Metadata asociada a los modelos:** Incluye documentaci贸n y metadata asociada a cada modelo entrenado, como m茅tricas de rendimiento, configuraci贸n utilizada, fecha de entrenamiento, etc. Esto proporciona contexto adicional sobre cada versi贸n del modelo y facilita su gesti贸n.

4. ## **Pipeline de entrenamiento continuo.**

    El pipeline de entrenamiento continuo es un proceso automatizado que ejecuta tareas de entrenamiento de modelos regularmente en respuesta a cambios en el c贸digo o nuevos datos disponibles. Este proceso implica la definici贸n del flujo de trabajo, la automatizaci贸n del proceso mediante herramientas de integraci贸n continua, la conexi贸n del repositorio de c贸digo, la especificaci贸n de eventos que activan el pipeline, el preprocesamiento de datos, el entrenamiento del modelo, la evaluaci贸n del rendimiento del modelo, y finalmente, el despliegue o almacenamiento del modelo entrenado. Este enfoque permite una mejora continua del modelo en un entorno automatizado y controlado.

5. ## **Propuesta de Monitoreo**

    - Para monitorear eficazmente un **ML Pipeline**, es fundamental seleccionar m茅tricas apropiadas que proporcionen una visi贸n completa del rendimiento del modelo y del proceso en general. Algunas m茅tricas propuestas y su importancia incluyen:

        **Precisi贸n del modelo:** Mide la proporci贸n de predicciones correctas sobre el total de predicciones realizadas. Es importante porque indica la exactitud del modelo en la clasificaci贸n de datos, lo que permite evaluar su capacidad para tomar decisiones precisas.
    
        **Recall:** Mide la proporci贸n de instancias positivas que fueron correctamente identificadas por el modelo. Esta m茅trica es esencial para evaluar la capacidad del modelo para encontrar todos los casos positivos, lo que es cr铆tico en aplicaciones donde la detecci贸n de casos positivos es prioritaria.
    
        **F1-score:** Es una medida que combina la precisi贸n y el recall en una sola m茅trica. Es 煤til para tener una visi贸n equilibrada del rendimiento del modelo, especialmente cuando hay un desequilibrio entre las clases de inter茅s.
    
        **Tiempo de entrenamiento y de predicci贸n:** Estas m茅tricas son importantes para evaluar la eficiencia del pipeline. Un aumento en el tiempo de entrenamiento o predicci贸n puede indicar problemas de escalabilidad o rendimiento que deben abordarse.

    - Para configurar alertas para cambios y problemas en la calidad de datos en el modelo implementado, se pueden considerar las siguientes estrategias:

        **Monitoreo de datos de entrada:** Establecer alertas para detectar cambios significativos en la distribuci贸n de los datos de entrada. Esto podr铆a indicar problemas de calidad de datos, como la presencia de valores at铆picos o la falta de datos relevantes.
    
        **Validaci贸n de datos en tiempo real:** Implementar controles de calidad de datos en tiempo real durante el proceso de predicci贸n para detectar datos corruptos o inconsistentes. Esto podr铆a incluir la detecci贸n de valores faltantes o fuera de rango, as铆 como la comparaci贸n con valores esperados.

    - Para configurar alertas y acciones para una posible degradaci贸n del modelo, se pueden considerar las siguientes estrategias:

        **Seguimiento de m茅tricas de rendimiento:** Establecer umbrales para las m茅tricas de rendimiento del modelo y configurar alertas para detectar una disminuci贸n significativa en estas m茅tricas. Esto podr铆a indicar una degradaci贸n en el rendimiento del modelo que requiere atenci贸n.
    
        **Implementaci贸n de pruebas A/B:** Comparar el rendimiento del modelo actual con versiones anteriores utilizando pruebas A/B. Si se detecta una diferencia significativa en el rendimiento, se pueden activar alertas para investigar y abordar posibles problemas.
